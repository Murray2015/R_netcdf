---
title: "R Notebook 3 - masking NetCDF data"
---

Hello, and welcome to the final R climate notebook. In the first R notebook we explained what variables and function are (where we store climate data and how we operate on climate data, respectively), we described using simple mathematical operations on variables (which therefore allows us to do useful things to our data, e.g. such as change units - if you have a matrix of temperatures in degrees Celsius in a variable called temp, then temp+273.15 would change every temperature in temp to Kelvin), and we described how to plot simple time series data. In the second R notebook we explained the NetCDF file format and how we work with it in R, including the standard workflow of opening the file, viewing the header (metadata), extracting variables, extracting attributes, and closing the file. We then explained slicing out a specific time slice to make a map. We flipped the time slice, showed ways to plot with different colour palettes, and how to save plots. 

In this final notebook, we will read some data from a NetCDF file and make a difference map to show the changes between two different time slices. We will then use our subsetting skills to slice our data into regions of interest, e.g. just the tropics or just a longitude slice. We then cover how to use a mask in a separate NetCDF file to mask out areas and regions of arbitrary shape, allowing us to subset geographic regions such as individual continents, or individual habitat areas. We also show how to find summary statistics for any of these subsetted areas. Finally, we show how to extract a time series at a particular location, so we can see how a variable has changed over time. Let's get started! 


## Read in data from NetCDF
We start by reading in our NetCDF data. We use the setwd() function to set the working directory to the location of our saved NetCDF file. We then use the library() function to load the ncdf4 package so we can open the NetCDF file. We use the nc_open() function to open a connection to the NetCDF file and save it to a variable. We use print() to view the header of the NetCDF file, and the ncvar_get() function to extract the lat, lon, time and yield_mai variables - which we found the names for from the print() function. We then get the attributes we want with the ncatt_get() function, and close the file connection with the nc_close() function. This was all explained in detail in the previous R notebook. Finally we change the _FillValues in the NetCDF file to NAs so R does not plot them, and extract the first yield slice and flip it upside down, ready for plotting. Remember to run these code chunks you must have this document open in R studio, then click in the grey box below and press *Ctrl+Enter* on a Windows computer or *Cmd+Enter* on a mac. 

```{r}
## Use the workflow from R notebook 2 to read in the NetCDF file 
# Set the working directory to where the data files are saved
setwd("~/Documents/scratch/R_netcdf") # This is the file path to where I have saved my data files on my computer. Your file path will be different. Either use Windows Explorer (Finder on a mac) to find the file path, or use the menu at the top of R studio to set the working directory instead. If you want to use the menu instead of this line of code, at the top of R studio click Session >  Set working directory > Choose directory, and navigate to the folder where the data files are saved.
```

Then read the data into R
```{r}
# Load the ncdf4 library into R. (note, we installed this with install.packages() in Notebook 2)
library("ncdf4")
# Open a file connection to the NetCDF file
ncfile <- nc_open("lpj-guess_agmerra_fullharm_yield_mai_global_annual_1980_2010_C360_T0_W0_N60_A0_1deg.nc4")
# Print the NetCDFs header
print(ncfile)
# Extract variables from the NetCDF file
lat=ncvar_get(ncfile, 'lat')
lon=ncvar_get(ncfile,'lon')
time=ncvar_get(ncfile, "time")
yield = ncvar_get(ncfile, 'yield_mai')
# Extract attributes from the NetCDF file
yield_units=ncatt_get(ncfile, "yield_mai", "units")
yield_fillvalue <- ncatt_get(ncfile,"yield_mai","_FillValue")
# Close the NetCDF file connection
nc_close(ncfile)
# replace netCDF fill values with NA's
yield[yield==yield_fillvalue$value] <- NA
# Extract the first time slice from the NetCDF file as a matrix, and store in a variable called first_yield_slice. 
first_yield_slice = yield[,180:1,1]
```

Lets start by using the image function to see what the data looks like. 

```{r}
# Make a quick plot of the first time slice 
image(first_yield_slice)
```

Hmm, that's a bad start. The map seems to be empty - i.e. we seem to have no data in the slice. This normally means we have done something wrong, but there are occasions when it's just a dodgy file in one way or another. 

Let's try checking the dimensions of the file to see if we can find out what is wrong. 

```{r}
# The last plot seemed to have no data, so to trouble shoot, lets check the matrix of data in first_yield_slice has the dimensions we expect with the dim() function
dim(first_yield_slice)
```

Hmm, the dimensions seem to be what we are expecting. Maybe it's just a dodgy file. Let's try the second time slice instead. 

```{r}
# The dimensions seemed fine, so to continue to troubleshoot let's trying selecting a different time slice. Maybe it's just the first time slice that is empty. 
first_yield_slice = yield[,180:1,2]
image(first_yield_slice)
```

Oh. The second slice is fine. Must just be a dodgy file. *Note that I have kept this example in this R notebook to show what working with data for the first time is like. I had a problem, so I tried to work out what the problem was by trying a couple of different functions.* This is totally normal when working with data in science. Anyway, let's carry on. 

## Making a difference map 
A common thing to want to do is to see a change over time in some variable. For example, how global temperature has changed over time, or how productivity has changed in London over time, etc. If you want to look at the difference in just one place, a line graph is a good choice. (often called a "time series plot", as change over time is time series data). But what if you want to look at how the whole world has changed over time? One good way of doing this is to look at the difference between two time slices. Remember the "difference" just means to subtract the later time step from the earlier. Areas which are positive then show an increase over time in whatever variable we are considering, while negative values correspond to decreases over time in whatever variable we are considering. Let's try this now to look at the difference between time slices 2 and 3. 

```{r}
# Let's make a difference map by subtracting one time slice from another. 
# Load the fields package for plots with a colourbar. We installed the fields package with install.packages() in Notebook 2.
library("fields")
# Select the second time slice and store in a variable called yield2. Note the 180:1 in the lattitude space, which flips the matrix (as it is upside down in the yield variable)
yield2 = yield[,180:1,2]
# # Select the third time slice and store in a variable called yield3. Note the 180:1 in the lattitude space, which flips the matrix (as it is upside down in the yield variable)
yield3 = yield[,180:1,3]
# Find the difference between the two matrixs of data. 
yield_difference = yield3 - yield2
# Make a plot of the difference
image.plot(yield_difference)
```


Hmm. The map is pretty to look at, and the data is pretty cool. However it would be much easier to understand what is happening globally with a polar colour palette - i.e. one that goes from one colour to white to another colour. The RColorBrewer package we introduced in the last notebook has several of polar colour palettes, including a very fetching red - white - blue one:

```{r}
# Load the RColorBrewer library (which we installed in Notebook 2 with the install.packages() function) to give us more colour ramps.
library("RColorBrewer")
# Remake the difference map with a polar colour pallete (i.e. cold to hot colours) with 9 levels. Note the rev() function used to reverse the colour pallete, as by default it goes from red to blue not blue to red. 
image.plot(lon, lat, yield_difference, col=rev(brewer.pal(9,'RdBu')))
```

Sometimes there is a lot of increase but almost no decrease in something over time (or the opposite, lots of decrease and little increase). Plotting this kind of data can end up with the white of the colour palette not being centered over 0 (remember if we are looking at a difference map made by subtracting one time slice from another a value of 0 means there is no change, so this is important for understanding the data!). A polar colour palette such as what we are using needs to be centered at zero, otherwise it gives a very skewed message. A useful cheat to handle this in R is to make a single square in our "yield_difference" matrix the positive largest absolute value in the whole matrix, and another square the negative largest absolute value in the whole matrix. This means the colourbar will be perfectly centered at 0, because the colourbar fit's itself between the smallest and largest values. However note, *you shouldn't do this before extracting any summary statistics* about the data (because we are actually changing two values of the data), and also *you shouldn't do this if the data is low resolution*, as you may be able to actually see the values you have changed. 
```{r}
# Cheat at centering the colourbar at 0 by making the lowest right hand corner the posative maximum absolute value, and making the square next to it the negative maximum absolute value. Do not do this before taking summary statistics of the data, as we are actually changing the data to make it plot how we want it to. Also do not use with low resolution data, as you may be able to see the values you have changed. 
yield_difference_altered = yield_difference
yield_difference_altered[1,1] = max(abs(yield_difference_altered), na.rm=T) # na.rm=T is short for na.rm=TRUE. This means to remove the NA values before finding the maximum of the absolute value. If na.rm=T isn't here, the abs function will return NA and the code won't work as expected. Remember many functions in R will return NA if there are any NAs in the data, kinda as a warning. For example "max(c(1,5,NA, 500))" will return NA, but "max(c(1,5,NA,500), na.rm=T)" will return 500. 
yield_difference_altered[2,1] = -max(abs(yield_difference_altered), na.rm=T) # na.rm=T is explained above.
image.plot(lon, lat, yield_difference_altered, col=rev(brewer.pal(9,'RdBu')))
```

OK this is cool. Now that we've set the colour bar we can see that between time slices 2 and 3, actually most of the world only changes a tiny bit. But certain regions seem to be changing much more. 

## Summary statistics on data 
You might well want to take summary statistics for a grid of data. This is incredibly easy in R. Say, for example, you wanted to find the mean of our yield_difference, i.e. we wanted to find the average global change between slices 2 and 3:

```{r}
# Find the mean of our difference between slices 2 and 3. 
mean(yield_difference)
```
Oops, we forgot the na.rm=T function argument. Remember many functions in R return NA if there are *any* NAs in the data, as a warning there are NAs there. Let's rerun it:

```{r}
# Find the difference between slices 2 and 3, removing NAs before. 
mean(yield_difference, na.rm=T)
```

Similarly, lets find some other summary statistics for our slice:
```{r}
# Find other summary statistics for the difference between slices 2 and 3. 
median(yield_difference, na.rm=T)
sd(yield_difference, na.rm=T) # the sd function returns the standard deviation. 
max(yield_difference, na.rm=T)
min(yield_difference, na.rm=T)
```


## Subset only equatorial regions 
You might want to find the mean (average) yield over a smaller area than the whole world. This is easy to do. 
```{r}
# Make a temporary slice with the data flipped the right way up. Makes everything less complicated! 
temp_slice = yield[,180:1,2]
# The tropic of Capricorn is at 23 degrees north. However remember our matrix starts at 0 at the bottom corner and goes up to 180 at the top corner, rather than the usual -90 degrees of the south pole and +90 degrees at the north pole. So we need to do 90 + 23 to find the tropic of capricorn on our grid. 
tropic_capricorn = 90+23
# Similar to the tropic of Capricorn above, the tropic of cancer is at is at 23 degrees south. However our matrix starts at 0 at the bottom corner and goes up to 180 at the top corner, rather than the usual -90 degrees of the south pole and +90 degrees at the north pole. So we need to do 90 - 23 to find the tropic of cancer on our grid. 
tropic_cancer = 90-23 
# Subset our grid with the square bracket notation. leave the first space blank to select all of the lonitudes. The use the colon notation to select the range of values between the tropic of Cancer and the tropic of Capricorn. 
tropics_yield_slice = temp_slice[ , tropic_cancer:tropic_capricorn]
# Make a quick plot of our subsetted data. It will obviously look distorted as it is being streched by the image function. There are several ways to make a correctly scaled map for a subset, but that is outside of the scope of this R notebook. 
image(tropics_yield_slice)
```
It might then be a smart idea to run summary statistics on just that tropics_yield_slice. Then you can find the average yield in the tropics. 

A similar trick can be used to subset the polar regions, but for this we need to combine it with the concatenate function "c()". Remember the concatenate function "sticks things together" into a vector. In the example below, we need the concatenate function because the poles have a big gap between them, so to subset them into the same grid we get the north polar region with the 180:polar_north, and we get the south polar region with the polar_south:1, and then we concatenate them together with the c() function. Remember the grid will look strange because from the maps above it appears most of the polar land masses haven't been modeled. It will also look strange because the southern polar regions and the northern polar regions are not normally plotted next to each other! Make sure you realize this example is mainly for subsetting the grid so that you can find summary statistics for the polar regions, not for plotting! 

## Subset only polar regions 
```{r}
# The polar regions are regions above 60 degrees north and below 60 degrees south lattitude. However remember our grid goes from 0 to 180 at the sides, not from -90 to +90. Therefore to get the correct locations we do 90-[lattitude of interest] and 90+[lattitude of interest]
polar_south = 90 - 60
polar_north = 90 + 60 
# use the square bracket notation to subset our grid of data. Leave the first space before the comma blank to select all longitudes. The second space is a little complex. We use 1:polar_south to get the south polar region, and polar_north:180 to get the north polar region. We then use the concatenate function "c()" to stick the two blocks of data together to allow subsetting. This is a little complex I realize, but just copy and paste this code if you need it. 
polar_yield_slice = temp_slice[ , c(1:polar_south, polar_north:180) ]
# Make a quick plot of the data. Note it will look weird because Antarctica and lots of Arctica Canada and Greenland don't appear to have been modelled. However you can see the top of Norway and parts of Russia. 
image(polar_yield_slice)
```

## Subset Longitude slices 
The exact same idea can be used to extract a longitude slice. (In fact, hopefully you are starting to see the same ideas about how to select subsets of data over and over again).
```{r}
# The longitude bounds for north and south America are roughly 160 degrees west to 30 degrees west. However remember our matrix goes from 0 at the left hand side to 360 at the right hand side, rather than the more familliear -180 to +180. Therefore we need to do 180-160 for 160 degrees west and 180-30 for 30 degrees west.
lat1 = 180 - 160
lat2 = 180 - 30
# Select the longitude slide using the lat1:lat2 colon notation to select the range of values. Leave the space after the comma blank to select all values for lattitude. 
polar_yield_slice = temp_slice[lat1:lat2, ]
# Make a quick plot of the lattitude slice.
image(polar_yield_slice)
```

## Combining it - subset a box around a country of interest 
You might have guessed that if we can subset data with latitude and with longitude (and with time - every time we have taken a time slice we have just be subsetting by time!), then we can combine subsetting latitude and longitude to select a particular region. 
```{r}
# Subset both lattitude and longitude to find australia. Here I just played with values to find the correct bounds for Australia, rather than the method above. 
australia_yield_slice = temp_slice[290:335 , 45:80]
# Make a quick plot of the data.
image(australia_yield_slice)
```
## Subset using a mask 
So we can now subset any type of rectangular box or slice we want from out matrix of data that we extracted from a NetCDF file. But what if we want an area more complex than a rectangular box? This is best done with a mask. A mask is normally a NetCDF file filled with the number 1 everywhere in a region we want to extract, and filled with NA everywhere else. If we extract our mask into a variable, and then multiply our mask by our data, then everywhere multiplied by 1 will stay the same, while everywhere filled with NA will become NA. This is because in R, anything multiplied by NA becomes NA. (This is kinda like how in maths, anything multiplied by 0 becomes 0. But 0 can actually have meaning in climate data, so we don't want to set everywhere outside our mask to zero.). 

Let's quickly see an example. This example is sort of like making out one place we want to get rid of:
```{r}
# Demonstrating the idea of how to subset data in R using a mask. We want to have a mask filled with NAs where we want to not have data, and 1s where we do have data.
pretend_data1 = c(0,1,2,3,4,5)
pretend_mask1 = c(1,1,NA,1,1,1)
# When we multiple our mask and our data, the data will stay the same where it is being multiplied by 1, but will change to NA where it is multiplied by NA. This example demonstrates masking out just one value. 
pretend_data1 * pretend_mask1
```

Or a similar example, this example is more like making out all of the rest of the world to extract just one country or region:
```{r}
# Demonstrating the idea of how to subset data in R using a mask. We want to have a mask filled with NAs where we want to not have data, and 1s where we do have data.
pretend_data2 = c(0,1,2,3,4,5)
pretend_mask2 = c(NA,NA,NA,1,NA,NA)
# When we multiple our mask and our data, the data will stay the same where it is being multiplied by 1, but will change to NA where it is multiplied by NA. This example demonstrates masking out all except one value.
pretend_data2 * pretend_mask2
```

Hopefully the idea of masking to get rid of data is pretty clear! Now lets actually do it with a real mask. Here we skip a load of steps in reading the NetCDF as I already know what is in the file. I still print the header of the NetCDF file, as there is almost always some useful information in the header:
```{r}
# Read in a NetCDF file containing a mask for forest regions around the world. Here we use the same NetCDF workflow as shown in Notebook 2, but much reduced. 
# Open a file connection to the NetCDF containing the mask values
ncfile = nc_open("ESA_forest_9regions_v2_1deg.nc")
# Print the header information for the NetCDF file
print(ncfile)
```


OK, so immediately we have found useful information in the header. The header says:

>double region_mask[lon,lat]   
            Comment: 1=Tropical broadleaved evergreen, 2=Tropical broadleaved deciduous, 3=Other Tropical (<23 degrees), 4=Temperate broadleaved evergreen, 5=Temperate broadleaved deciduous, 6=Needleleaved evergreen, 7=Needleleaved Deciduous, 8=Broadleaved/Needleaved mixed forest, 9=Other

So it seems like this file is a mask for many different regions (in this case forest regions). Each region seems to be filled with a common value, going from 1 to 9. Let's try extracting the values into a variable called "mask" and plotting the mask to see if we are correct: 


```{r}
# Use the ncvar_get() function to get the values of the mask
mask = ncvar_get(ncfile, 'region_mask')
# Close the connection to the NetCDF file.
nc_close(ncfile)
# Make a quick plot of the values in the mask file 
image.plot(mask, col=rainbow(9))
```

Yep, looks like we are correct. However, as we talked about earlier, we preferably want this data mask to be in the form of 1s where we want to extract the data, and NAs everywhere else. Luckily we can do this in 1 line of code in R. Meet the "ifelse()" function. The ifelse() function takes a condition as it's first argument (for example mask==3, which means select only the places where the mask equals 3), the value to change to when that condition is true as it's second argument (which will always be 1 for us), and the value to change to when that condition is false as it's third argument (which will always be NA for us). Let's see this in action to make a mask for tropical broadleaved deciduous forests, select those by multiplying our data by our new mask, and then making a map of our selected data: 

```{r}
# After plotting the mask, we see that the format of the mask is numbers from 1 to 9, rather than the 1s and NAs that we want. Here we make a new mask for tropical broadleaved deciduous forest using the ifelse() function. This line of code makes a matrix where tropical broadleaved deciduous forest are set to 1, while the rest of the matrix is set to NA. This matrix is then saved to the variable tropical_broad_dec_mask.
tropical_broad_dec_mask = ifelse(mask == 2,1,NA)
# Select that data by multiplying the data in first_yield_slice by the mask. 
first_yield_slice_tropical_broad = first_yield_slice * tropical_broad_dec_mask
# Make a plot of our subsetted data. 
image(first_yield_slice_tropical_broad)
```

And then after we have subsetted/masked/selected (these words all mean the same thing here) our data, we can find summary statistics for it. Incase it has become confusing why we are finding summary statistics of things, it's because often a summary statistic is the best way of answering a scientific question. Obviously a scientic question isn't normally "can you subset a broadleaf forest?" - which after doing the tutorial, the answer is yes, you can subset a broadleaf forest! The scientific question is more likely to be something along the lines of "What is the average yield of broadleaf forests". To answer this, you would want to take the mean (another way of saying the average) of the broadleaf forests. So let's do this, lets find  Don't forget the na.rm=T (or na.rm=TRUE) function argument! 

```{r}
# Summary statistics are things like mean, median, maximum, minimum, interquartile ranges, etc. Summary statistics are often the best way to answer scientific questions, such as "what is the maximum modeled temperature in a tropic broadleaf forest". Let's see an example of how easy it is to get a summary statistic for the yield of the tropical broadleaf forests
mean(first_yield_slice_tropical_broad, na.rm = T)
```

Let's do a second of subsetting a region then finding a summary statistic on the subset, just to show it again. Remember I am just showing you how to get a summary statistic here, which summary statistic (e.g. mean, meadian, minimum, etc) you would choose would depend on the scientific question you were trying to answer. 

```{r}
# Make a new mask for tropical broadleaved deciduous forest using the ifelse() function. This line of code makes a matrix where tropical broadleaved deciduous forest are set to 1, while the rest of the matrix is set to NA. This matrix is then saved to the variable tropical_broad_dec_mask.
tropical_broad_ever_mask = ifelse(mask == 1,1,NA)
# Select that data by multiplying the data in first_yield_slice by the mask. 
first_yield_slice_tropical_broad_ever = first_yield_slice * tropical_broad_ever_mask
# Make a plot of our subsetted data. 
image(first_yield_slice_tropical_broad_ever)
# Find the maximum yield in this subset
max(first_yield_slice_tropical_broad_ever, na.rm=T)
```

## Time series 
One final thing we might want to do is extract a time series at a certain location. Can you think what this would look like in terms of the code?
Yes it's really simple. Just a single value for each the lat and long, and then leave the time slice empty to select them all (remember that our yield data is a cube of data with the shape yield[longitude,latitude,timeslice], so yield[250,60,] would select all time slices at the location 260 degrees from the left hand margin and 60 degrees up from the south pole). 
Let's extract a quick time series and plot it

```{r}
# Here we extract a time series from the yield data by specifying a single lattitude and longitude, but then leave the third space inside the square brackets blank to select all time slices at that lat/long location. 
time_series_australia = yield[250,60,]
# Plot the time series we have just extracted. 
plot(time_series_australia, type='l', xlab="Time step", ylab='Yield')
```


Or sometimes you might want to make a histogram of the values to see a different way of looking at their spread: 

```{r}
# Finally, make a histogram of our time series data. Just because we can. 
hist(time_series_australia, col='black', main='', xlab='Yield')
```


And we are finished! As with the other two tutorials, I strongly recommend that you go back through this tutorial at least one more time. There is just too much information to take in in one read through. But seriously, congratulations! You can now do a huge amount of things in R. You can manipulate data to change it's units via simple mathematical operations. You can install and load new packages for free. You can read and work with data files hundreds of times too big to open in excel. You can make and save publication quality maps and graphs. You can select, mask and filter data you want. You can find summary statistics for areas and regions of the world, and you can make several types of plot to summarize it. Well done! I hope you have found this series of R notebooks helpful. Good luck in using these skills for your own work, and enjoy! 

# Bonus!! If you want to continue learning R... 
So this tutorial covered a gigantic amount in a short space of time. R can do a huge amount, and is used in a huge number of different fields. R is used extensivly in tech companies such as Google and Microsoft, is used in every university in the world, and in many major companies in their data analysis and data science teams. R can make your coursework in many modules at university easier too - just use your imagination! Whether for fun, for a career, or just to make some of your coursework easier, you might want to keep learning R. There are a million tutorials, books and videos online to teach you R for free. However R comes with a package called Swirl, which teaches you R from inside R studio. You can install it in the usual way (install.packages("swirl")) and then load it in the usual way (library("swirl")). You can then start swirl by typing swirl() at the R console at the bottom of the screen. Download one of the free courses and continue learning R. :) 


```{r echo=FALSE, results='hide'}
# This line of code extracts all R code from this document
knitr::purl("Rmd_script_3_masking.Rmd", output="Script_3_R_code_only.R")
```
