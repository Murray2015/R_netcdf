---
title: "R Notebook 2 - working with NetCDF data"
---

Hello! This is the second R notebook on working with climate data. In the last notebook, we introduced the programming constructs of a "variable" and a "function". We then worked with 1 and 2 dimensional ASCII data to make some scatter plots. In this notebook, we will introduce new functions for opening and working with a type of file called a NetCDF file, which contains 3 dimensional and higher dimensional data. But don't panic, we will still just be storing this new data in variables, and working with the data with functions, so you already know all the theory. **Just to remind you, if you are feeling like there is loads of code to remember and it's a bit overwhelming, you don't have to remember the code at all**. The idea is that you can copy and paste the code and alter it to do what you want to do.  

Anyway, let's get started! 


# 3 dimensional climate data - NetCDF files.
As mentioned in the last R notebook, the first thing we always need to do is set our working directory to the folder where we have saved the data. Otherwise R doesn't know where to look for the data. We run the code in the grey code chunk below by clicking in the grey box and pressing *Ctrl+Enter* or *Cmd+Enter* for mac users (assuming you have opened this document in R studio), but **first you need to change the file path inside the setwd() function to your file path**. To save you some typing, this can also be done from the menu at the top of R studio. Go to Session >  Set working directory > Choose directory, and navigate to the folder where the data files are saved.

```{r}
# Set the working directory to the folder where the data is saved.
setwd("~/Documents/scratch/R_netcdf") # This is the file path to where I have saved my data files on my computer. Your file path will be different. Either use Windows Explorer (Finder on a mac) to find the file path, or use the menu at the top of R studio to set the working directory instead. If you want to use the menu instead of this line of code, at the top of R studio click Session >  Set working directory > Choose directory, and navigate to the folder where the data files are saved.
```

You probably haven't heard of NetCDF as a file type. NetCDF files are files that normally end with the file extension .nc or sometimes .grd. NetCDF files are used for various types of climate data and geophysical data. The structure of data inside a NetCDF file is like a stack of spreadsheets on top of each other, where the x and y variables are normally latitude and longitude. See the picture below. 
![The structure of a netcdf file.](netcdf.gif)
The X and Y variable refer to latitude and Longitude for climate data, although not always. Often a NetCDF file contains data for the whole world, but they can just contain data for a part of the world. The random numbers in each square in the diagram represent the actual data for the variable of interest - this could be mean annual temperature, or rainfall, or ozone concentration, or anything. The time axis doesn't always exist in a NetCDF file. If the time axis doesn't exist, the structure of the file is like just the first orange layer in the NetCDF diagram above, without the pink and green layers.

To work with NetCDF files in R, you need to install a couple of packages. R is such a popular language for science and data analysis because it has thousands of packages which can be downloaded (for free!) with a single line of code. These packages range from forecasting time series for weather analysis or stock prices, to working with geospatial data, to higher performance parallelisation routines, to adding pictures of cats to plots (yes, really!) to..... you get the idea. If you can think of a scientific problem, there's probably already a package for it in R. 

In R, you install a package once using the "install.package()" function. This normally only needs to be done once on a computer. Then the package must be loaded into R with the "library()" function. This needs to be done every time you restart R. Let's load the ncdf4 package. 

```{r}
# Install the "ncdf4" package from the internet. This normally only needs to be done a single time on a computer, and then it is installed forever. 
install.packages("ncdf4")
```

You should see a load of both black and red text flash by on the screen. The important bit is the last few lines, which should say thing have been loaded OK. Specifically, the final line should say "* DONE ([the package name])". The package has now been installed, but it still needs to be loaded into R (and loading the package needs to be done at the start of every script with a package in it). Let's do this now. 

```{r}
# Load the "ncdf4" package into R. This needs to be done at the start of every R script that uses the package. 
library("ncdf4")
```
You shouldn't see any output from running this line of code, but we can now use the functions in the ncdf4 package. 

What we are going to walk you through doing in the next few code chunks is the standard workflow for using a NetCDF file in R. This workflow is as follows:
1. Open the NetCDF file connection in R with the "nc_open()" function
2. Find out what is actually inside the NetCDF file with the "print()" function
3. Extract the variables we want to use from the NetCDF file using the "ncvar_get()" function
4. Close the NetCDF file connection in R with the "nc_close()" function.

Each of the steps above is quite easy, so don't panic! 

First, we want to open the NetCDF file and look at the ranges of different variables. Luckily this is quite easy in R. First we use the ncdf4 library to open a connection to the file and store this connection in a variable, and then we use the print function to print a summary of the file. Lets do this now. Remember if you haven't run the install.packages() and the library() functions, then R will complain that it "can't find" the function - which means R doesn't know what these functions are because they haven't been loaded yet. 

```{r}
# Open a connection to the NetCDF file and store this connection in a variable called ncfile. (don't worry about what we mean by a "connection" to the file, this will become clear throughout the examples.)
ncfile <- nc_open('2016722131556EnsembleGPP_MR_1deg.nc')
# Print the header of the NetCDF file (i.e. print the NetCDF file's metadata)
print(ncfile)
```

Ouch, that's quite a lot of text! Take a moment to read it all. Even though the output looks confusing, this is the same sort of output you will get from every NetCDF file you open with R, so it will become easy after you've done it a couple of times. 

The first few lines of the output say:
> 3 variables (excluding dimension variables):
double time_bnds[bnds,time]
float gpp[lon,lat,time]
  (some other output)
float std[lon,lat,time] 
  (some other output)

This tells us there are 3 variables in this NetCDF file. The first variable is time_bnds, the second is gpp, and the third is std. You will often see "double" and "float". This refers to how many decimal places the computer is storing numbers as. The important bit is that it is just a normal decimal number.  

The next paragraph of the print() output tells us information about the variables in the NetCDF file:

>     4 dimensions:
time  Size:360
  (some other output)
bnds  Size:2
  (some other output)
lon  Size:360
  (some other output)
lat  Size:180
  (some other output)

This tells us that the dimensions of the file are latitude (stored in the variable called "lat"), longitude (stored in the variable called "lon"), and time (stored in the variable called "time"). There is a forth variable called bnds - don't worry about this, we don't need it. 

After this, we have a long paragraph which starts with 

> 13 global attributes:
(loads of output)

In a NetCDF file, the global attributes are normally useful things like who made the file, when it was made, a description, and other useful information which is often called meta-data. 

We now understand a bit about our NetCDF file. The next step is to extract variables in the NetCDF file into variables in R. To do this we use the "ncvar_get()" function. The function arguments "nc=" refers to the NetCdf file, while the "varid=" function argument refers to the variable name *in the NetCDF* file. This is why we needed to use the print() function in the last step; to find out the variable names. 

```{r}
# Extract the 'lat' variable in the netcdf file, and store it in a variable called 'lat' in R.
lat=ncvar_get(nc=ncfile, varid='lat')
# Extract the 'lon' variable in the netcdf file, and store it in a variable called 'lon' in R.
lon=ncvar_get(nc=ncfile,varid='lon')
# Extract the 'time' variable in the netcdf file, and store it in a variable called 'time' in R.
time=ncvar_get(nc=ncfile, varid="time")
# Extract the 'gpp' variable in the netcdf file, and store it in a variable called 'gpp' in R.
gpp = ncvar_get(nc=ncfile, varid='gpp')
```

We now have 4 variables in R holding the information we extracted from the variables inside the NetCDF file. We want to know what is inside these variables. We could just print their whole contents to the screen by just running their name in the usual way. However we know that some of these variables might be very, very big, and this might cause the computer to crash. A safer way is to use the "length()" function or the "dim()" function to see how long the variable is. Lets do this:

```{r}
# Use the length function to see how long each variable is
length(lat)
length(lon)
length(time)
length(gpp)
```

OK, so that final variable gpp has 23 million entries. Probably a good thing we didn't just print that to the screen. (Also, if you're still thinking why are we using R not excel, try opening a 23 million line long file in excel). 

We have now extracted all the data we need from the NetCDF file connection. We can now close the connection to the file. This frees up some computer memory for us. Note that we didn't need to do this in the last notebook for the "read.csv()" and "read.table()" functions, which close the data file automatically. 

```{r}
# Close the NetCDF file connection
nc_close(ncfile)
```

Now that we have extracted all the data in our NetCDF file, we are ready to start making some maps of the data! 

## Making our first map 
The data inside a NetCDF file (and therefore the data in our variables in R which we have extracted from the NetCDF files) is a rectangular grid of numbers called a matrix. In fact, because we have a time variable, we actually have a 3D cube of data - imagine a rubix cube of data, but with the dimensions of our data instead of the normal 3x3x3 rubix cube. 

Remember we extracted four data variables from the NetCDF file with the ncvar_get() function. Those variables were lat, lon, time, and gpp. 

Let's remind ourselves of the dimensions of our data:

```{r}
# Find the dimensions of the gpp variable
dim(gpp)
```

This output means we have 360 in the x dimension, 180 in the y dimension, and 360 in the z dimension. If we check back to the length of the variables from the print() function we can see this corresponds to lat, long and time. 

This is just a matrix of data, so we can extract any subset of it using the square bracket notation. Let's extract the first time slice of the data, and save it in a variable called first_gpp_slice. 

```{r}
# Extract the first time slice from the gpp variable
first_gpp_slice = gpp[,,1]
```

Remember using the square bracket notation to slice data in the last R notebook? In that notebook, use said how for 2D data the format is some_variable[x_dimension,y_dimension]. This means to select the first row of the first column would be some_variable[1,1]. In the previous notebook we also mentioned that if we leave the places before or after the comma inside the square brackets blank (like this: some_variable[,1] or some_variable[1,]) that we select all of that column or all of that row. 

Hopefully that is not too confusing so far. So we know our gpp variable is a 3D cube of data rather than a 2D grid. We can use the square bracket notation to extract the data like this: some_variable[x_dimension,y_dimension,z_dimension]. For our gpp variable, this corresponds to gpp[latitude,longitude,time]. Therefore running gpp[,,1] means give me all latitude and all longitude for the first time slice only. Obvious, you would change the final value if you wanted a different time slice, e.g. gpp[,,53] would give the 53rd time slice. 

Knowing all of this, if we run our trusty dim() function on our new variable first_gpp_slice, we should get results of 360 x 180 x 1, as we took all longitude and all latitude, at the first time only (not at all time slices). So essentially we took the first layer off our rubix cube. 

Lets check we get 360 x 180 x 1 with our dim() function. 

```{r}
# Sanity check the dimensions of our first_gpp_slice. Should be 360 by 180
dim(first_gpp_slice)
```

OK, so we get 360 x 180, which is the same as 360 x 180 x 1. So we now have a single time slice stored in a matrix. We can easily make a picture from a matrix using the image function:

```{r}
# Make a quick plot of the first time slice. 
image(first_gpp_slice)
```

Cool! But there is an obvious problem - the world seems to be upside down. Luckily this is easily fixed. We just slightly modify how we are slicing the gpp variable. You see, when we write gpp[,,1] to represent "give me all the latitude and all the longitude values for the first time slice", under the hood R is treating this the same as if we had written gpp[ 1:360 , 1:180 , 1 ]. Therefore to flip the matrix in the latitude direction, we just change the 1:180 to 180:1 to reverse it. See below: 

```{r}
# The map was upside down, so were we extract the first time slice again, but flip it's y axis as we extract it. This is what the 180:1 is doing. 180 is the greatest number and 1 is the least, therefore we are saying take the last value and put it first and take the second to last value and put it second, etc. It flips the matrix. 
flipped_first_gpp_slice = gpp[,180:1,1]
# Plot our new flipped matrix. 
image(flipped_first_gpp_slice)
```

OK, now we're cooking! This is a map of the first time slice of our gpp variable! But for it to be a decent map, we need a couple of things. First, it would be best to add a scale. It looks like the axes are currently just going from 0 to 1 as well - we probably want to change that. It might be useful to be able to change colour scales too. And maybe a title would be a good idea too. Let's set about modifying our plot. 

## Adding a legend 
So it turns out we have an immediate problem. Adding a legend to the image() function is really hard. Doh! The image function is still really useful as a quick first look at a matrix of numbers though. However it just so happens that in the fields package, some kind R programmer has modified the image() function into a new function called image.plot(), which has an automatic colour bar. It also allows us to specify the labels of the x and y axis, so we can actually display latitude and longitude rather than the strange 0 to 1 scale. Uncomment the install.packages line underneath to install the fields package, then run the library command to load the package and the make the map: 

```{r}
# install the fields package, which as the image.plot() function. Uncomment the line below (to "uncomment" just means to delete the '#' symbol at the start of the line) to run it for the first time.
# install.packages("fields")
# Load the fields package with the library() function
library("fields")
# Make a plot of our matrix using the image.plot() function, which adds a colourbar automatically. The first argument is the values to use for the x axis, the second argument is the values for the y axis, and the third argument is the actual data values. 
image.plot(lon, lat, flipped_first_gpp_slice)
```

Cool! Looking better already. There is a useful function called map() in R which allows us to add country outlines. This is often a good idea to add, as it shows there is no data at all for Antarctica, Greenland, and the Sahara. Note the add=T (short for add=TRUE), which adds to the current plot. Try changing some of the function arguments to customize the plot. 

```{r}
# Same as the previous plot code but...
image.plot(lon, lat, flipped_first_gpp_slice)
# ... add a low resolution set of coastlines over the top for context. 
map(database = 'world', lwd=1.5, add = T, col='black')
```

## Changing colour paletts 
There are a number of standard color palettes in R. The rainbow colour palette is standard in image.plot(). However a number of recent scientific articles have pointed out that rainbow colour palettes can draw the eye to unimportant features as some color changes act like contours differently to different people. Therefore simpler colour paletts can often be better for displaying scientific data. Let's install the RColorBrewer package to give us access to a load of useful color palettes. The RColorBrewer packages gives us access to the brewer.pal() function. This allows us to give a number of breaks in the colour palette we want (normally up to 9 or 10, depending on the palette) as the first function argument, and the name of the colour palette as the second argument. So brewer.pal(10, "RdBu") gives us a color palette from red to blue with 10 breaks in it. This is cool, but we know low numbers for our gpp data are normally displayed with cold colours in environmental sciences, so we use the rev() function to reverse the order, making us a blue to red colour palette. See below: 
```{r}
# Install the RColorBrewer package, to give us access to lots of extra colour paletts. Uncomment and run the line below the first time on a computer. 
# install.packages("RColorBrewer")
# Load the RColorBrewer into R with the library() function. 
library("RColorBrewer")
# The same plot and map commands as before, but with the prewer.pal(10,'RdBu) function, which gives us a Red to Blue color ramp with 10 levels. This is then enclosed with the rev() function, which reverses the order of the red-blue color ramp to give us a blue-red color ramp, which is more normal for Environmental sciences. 
image.plot(lon, lat, flipped_first_gpp_slice, col = rev(brewer.pal(10, "RdBu")))
map(database = 'world', add = T, lwd=1.5)
```

You can find more about what color palettes are found in the RColorBrewer on this link [https://earlglynn.github.io/RNotes/package/RColorBrewer/index.html](https://earlglynn.github.io/RNotes/package/RColorBrewer/index.html). Let's try the yellow-green-blue palette instead, just for practice: 

```{r}
# The same image.plot() and map() code as before, but with a yellow-green-blue color palette.
image.plot(lon, lat, flipped_first_gpp_slice, col = rev(brewer.pal(9,"YlGnBu")))
map(database = 'world', add = T, lwd=1.5)
```

OK, now lets make the plot itself a bit better. Lets add a title, and remove the x and y labels using the main=, xlab= and ylab= function arguments we have already learnt. Look back up at the output of the print(ncfile) near the top of this script for where I got the correct name of the variable and the units. If all of this is seeming like an overwhelming amount to remember, bear in mind you can just copy and paste code from this document and just modify names. You don't have to remember all of this. There is no exam on R syntax :) 

If you change just these arguments and run the code you will find half the title has been chopped off the side of the plot! Aggghhh! This is because the title is quite long, and R by default has a fixed amount of padding around plots which our long title runs over. This is rarely a problem, but this is one of those exceptions! We can fix this by calling the par() function (short for plot PARameters) and change the mar=c() argument (short for MARgins). The default for this is par(mar=c(5.1, 4.1, 4.1, 2.1)). A bit random, I know. This is for graphic design reasons that I imagine someone spent ages deciding on. The numbers refer to the bottom, left, top and right hand margins respectively. Changing the second or fourth number to a smaller value should fix our problem. 

Finally, we want to add the units of our plot to the legend. To do this I googled the image.plot function and found this page [https://www.rdocumentation.org/packages/fields/versions/9.6/topics/image.plot](https://www.rdocumentation.org/packages/fields/versions/9.6/topics/image.plot) which tells us that the legend.lab= argument allows us to specify the text, the legend.line= argument moves the legend text to the side so it is not underneath the legend labels, and the legend.mar= expands the legend margin. Try changing the values of different function arguments and rerunning the code block several times to get a feeling for what each argument does. 

```{r}
# Change the margins of the plot, to stop to padding cutting the ends off our very long title.
par(mar=c(5.1,3,4.1,3))
# Same image.plot() and map() code as last time, but remove x and y labels (with xlab= and ylab=), add a main title (with main=), add a legend lable (with legend.lab=), and adjust the location and padding of the legend label so it is not under the legend text (with legend.line= and legend.mar=)
image.plot(lon, lat, flipped_first_gpp_slice, col = rev(brewer.pal(9,"YlGnBu")), xlab="", ylab="", main="Carbon Mass Flux out of Atmosphere due to Gross Primary Production on Land", legend.lab="kg m-2 s-1", legend.line=4, legend.mar=7)
map(database = 'world', add = T, lwd=1.5)
```

## Colourblind friendly / printing in black and white friendly colors? 
A final quick note on a set of colour palettes found in Python and Matlab called Viridis, Inferno, Magma and Cubhelix, which have become popular as they are colourblind friendly, black and white printer friendly (try printing a rainbow colour palette in black and white - there ends up being several dark bands, making the colourmaps unusable in black and white) and perceptual (i.e. they don't have the random contouring effect in different peoples vision emphasizing different things). These are available in the viridis package. Check out this link for more on how to use the package [https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html](https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html), and see below for an example of using it: 

```{r}
# Install the colourblind and black and white printer firneds viridis colour palettes
# install.packages("viridis")
# load the viridis package 
library("viridis")
# Same par(), image.plot() and map() functions as before, but using the viridis colour palette.
par(mar=c(3,3,3,3))
image.plot(lon, lat, flipped_first_gpp_slice, col=viridis(256), xlab="", ylab="", main="Carbon Mass Flux out of Atmosphere due to Gross Primary Production on Land", legend.lab="kg m-2 s-1", legend.line=4, legend.mar=7)
map(database = 'world', add = T, lwd=1.5)
```

## Saving plots 
Finally, you might well want to save the plots for later use, use in reports or presentations, or whatever. Any plot (e.g. scatter graph, pie chart, map, etc) can be saved in R. 

Saving plots in R requires 2 extra lines of code. First, you open a graphic device using one of the following functions: png(), jpep(), pdf(), tiff(). After this, you run your normal plotting code. Then after your plotting code, add the line dev.off() to close the graphics device. 

Note that if you save plots as a pdf, you can then open them in Inkscape or Adobe Illustrator to modify further. 
```{r}
# Open a png graphcs device to export a plot, and make a plot which is 10 inches by 5 inches, and save at a resolution of 300 dpi.
png("gpp_map.png", width=10, height=5, units = 'in', res = 300)
# Same par(), image.plot() and map() functions as before, but using the plasma color palette from the viridis package.
par(mar=c(3,3,3,3))
image.plot(lon, lat, flipped_first_gpp_slice, col=plasma(256), xlab="", ylab="", main="Carbon Mass Flux out of Atmosphere due to Gross Primary Production on Land", legend.lab="kg m-2 s-1", legend.line=4, legend.mar=7)
map(database = 'world', add = T, lwd=1.5)
# close the png graphics device to complete exporting the plot. 
dev.off()
```

Note you need to run the whole chunk with *Ctrl+Shift+Enter*, Running it line by line with *Ctrl+Enter* will cause problems. After running this code, you should get an output saying 
null device
          1
which means it has successfully closed the graphics device. You should then have a plot saved in your working directory. 


## End of Notebook 2
Well done for reaching the end of Notebook 2. I'm genuinely proud of you - that was a lot of code. But you got through it, and if you understood even half of it you can now do a huge amount. As with the last R notebook, I recommend going through this code at least one more time and possibly several times. And definitely start trying to play with the code. Change bits on each line to see what happens. Get used to R throwing error messages, and get used to googling how to do things. From reading these guides you will now have a good idea of the sorts of things you can do with R.



```{r echo=FALSE, results='hide'}
# This line of code extracts all R code from this document
knitr::purl("Rmd_script_2_netcdf.Rmd", output="Script_2_R_code_only.R")
```


## Troubleshooting 

# The fields package won't install on my Mac! 
Ugh. This is a Mac thing - occasionally some packages wont find the right compiler. Try running this:

```{r}
install.packages("fields", type="binary")
```

if that doesn't work, use the university computers rather than your Mac. If you totally insist on using your Mac, then dig around on the internet for how to install xtools, the latest version of gcc, restart your computer, and try the above line again. But you do this totally at your own risk, if this is done wrong you can mess up your Mac. 

# There are loads of really big numbers in my data (or really negative)
Sometimes numerical models output null, or infinity, or some value that the creator thinks isn't "real" data but an artifact of whatever program they are running. Kinda like when you accidentally divide by 0 - if you remember back to GCSE, there is no such thing as dividing by zero. It can't be done. Sometimes things go wrong and they need to be hidden, or set to some placeholder value that we know corresponds to no data. Often the values 9999 or -9999 are used for this. 

The way we have taught reading the NetCDF files normally deals with this for you. But occasionally this doesn't work and we get these values still in the data, which causes big problems when making a map of the data or a plot. 

The proceedure to get rid of these values is the following: 
1. Find what value corresponds to "no data" by looking at the output of the "_FillValues" or "no_data" or "missing_values" attributes in the print(ncfile) output. 
2. Run the confusing line of code below, which will change those placeholder values to "NA" inside R, which won't be plotted, thus saving the day! 

The line of code below is short, but quite complex. What the line of code does, is use the square brackets notation to extract any values in the gpp variable which equal the value in gpp_fillvalues, and set those extracted values to NA. If you need to use this line of code in your own work, just copy and paste and change the variable names to the variable names in your work. 

```{r}
# replace netCDF _FillValues with NA's
gpp[gpp==9999] = NA
```

# There doesn't seem to be any data in my variable! 
First, run length() on your variable. If it has a length of 0, then you are correct. There is no data in your variable. You've probably incorectly put the data in the variable. 

# My data in my variable seems to be long, but only full of NAs?! 
First, use length() to see how big the variable is. If it's less than, say, around 200, then just print it to the screen and look at what is in it. If it is only full of NAs, then you have loaded the data incorectly. 
If the length() function shows the variable is much larger than 200, then you need to use different functions to look at the data. R has two useful functions, "head()" and "tail()", for looking at the first few or last few entries of a really long file without printing everything. Try that on the gpp variable, for example:
```{r}
# Use the head() function to see the first 5 entries of each variable, to help us understand our data. 
head(gpp)
```

The variable gpp seems to have lots of NAs (which means no data at that point). This might mean we have loaded it incorrectly, or it might just be because there is no data at that point. Lets look at the end of the variable:

```{r}
# Print the last few values in the gpp variable to see if it is still full of NAs. 
tail(gpp)
```

Hmm. The end of the variable also seems to be filled with NAs. We might now be slightly worried about whether all of the gpp variable is full of NAs. A quick way to check this without reading all 23 million values is to sum up the whole vector using the "sum()" function and see if it comes to a value greater than 0. If it does, then there is data in our gpp variable and we don't have to start searching through 23 million NAs to check. **Note** you *need* the na.rm=TRUE function argument in the "sum()" function, which tells R to remove the NAs before summing, otherwise R will return NA. 

```{r}
# Remove all the NAs, and sum up any numbers that remain. If we get a value of 0, there is no data in the gpp variable and it is all NAs, which probably means we have loaded the file incorrectly. If we get any value above 0 then the gpp variable does have some data in it. If the function returns NA, then we have forgotten to use the na.rm=TRUE function arguemnt. 
sum(gpp, na.rm=TRUE)
```

OK, the value is above 0. So we do have data somewhere in the gpp variable. It's OK. Phew! 

